[{"id":0,"href":"/docs/","title":"Documentation","section":"UnisonDB – Log-Native Database For AI And Edge Computing","content":"UnisonDB Documentation# Welcome to the UnisonDB documentation! This guide will help you understand, deploy, and use UnisonDB effectively.\nDocumentation Sections# Getting Started # Learn how to install, configure, and start using UnisonDB.\nArchitecture # Understand the internal design and components of UnisonDB.\nAPI Reference # Complete reference for HTTP and gRPC APIs.\n"},{"id":1,"href":"/docs/getting-started/","title":"Getting Started","section":"Documentation","content":"Getting Started with UnisonDB# This guide will walk you through installing UnisonDB, configuring it, and running it in both Server and Relayer modes.\nTable of Contents# Prerequisites Installation Running in Server Mode Running in Relayer Mode Prerequisites# System Requirements# Operating System: Linux or macOS Go: Version 1.24 or higher Installation# Building from Source# UnisonDB requires CGO to be enabled for LMDB bindings.\n# Clone the repository git clone https://github.com/ankur-anand/unisondb.git cd unisondb # Enable CGO (required for LMDB) export CGO_ENABLED=1 # Build the binary go build -o unisondb ./cmd/unisondb # Verify installation ./unisondb --helpExpected output:\nNAME: unisondb - Run UnisonDB USAGE: unisondb [global options] command [command options] [arguments...] COMMANDS: replicator Run in replicator (server) mode relayer Run in relayer (replica) mode fuzzer Run fuzzer for testing (if built with -tags fuzz) help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --config value, -c value Path to TOML config file (default: \u0026#34;./config.toml\u0026#34;) [$UNISON_CONFIG] --env value, -e value Environment: dev, staging, prod (default: \u0026#34;dev\u0026#34;) [$UNISON_ENV] --grpc, -G Enable gRPC server in Relayer Mode (default: false) [$UNISON_GRPC_ENABLED] --help, -h show helpBuilding with Fuzzer Support (Optional)# For testing and development, you can build with fuzzer support:\nCGO_ENABLED=1 go build -tags fuzz -o unisondb ./cmd/unisondbNote: When built with -tags fuzz:\nfuzzer command is available replicator command is disabled for safety To run fuzzer mode:\n./unisondb --config config.toml fuzzerInstallation to System Path (Optional)# # Move to system path sudo mv unisondb /usr/local/bin/ # Verify unisondb --helpRunning in Server Mode# Server Mode runs UnisonDB as a primary instance that accepts writes and serves reads.\n1. Generate TLS Certificates (Recommended)# For production or multi-node setups, generate TLS certificates for gRPC:\nUsing OpenSSL:\nmkdir -p certs \u0026amp;\u0026amp; cd certs # Generate CA openssl genrsa -out ca.key 4096 openssl req -new -x509 -key ca.key -sha256 -subj \u0026#34;/CN=UnisonDB CA\u0026#34; -days 365 -out ca.crt # Generate server certificate openssl genrsa -out server.key 4096 openssl req -new -key server.key -out server.csr -subj \u0026#34;/CN=localhost\u0026#34; openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365 -sha256 # Generate client certificate openssl genrsa -out client.key 4096 openssl req -new -key client.key -out client.csr -subj \u0026#34;/CN=client\u0026#34; openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365 -sha256 cd ..2. Create Server Configuration# Create a server.toml configuration file:\n## HTTP API port http_port = 4000 listen_ip = \u0026#34;0.0.0.0\u0026#34; ## gRPC configuration (for replication) [grpc_config] listen_ip = \u0026#34;0.0.0.0\u0026#34; port = 4001 cert_path = \u0026#34;./certs/server.crt\u0026#34; key_path = \u0026#34;./certs/server.key\u0026#34; ca_path = \u0026#34;./certs/ca.crt\u0026#34; # For development only - allows insecure connections allow_insecure = false ## Storage configuration [storage_config] base_dir = \u0026#34;./data/server\u0026#34; namespaces = [\u0026#34;default\u0026#34;, \u0026#34;users\u0026#34;, \u0026#34;products\u0026#34;] bytes_per_sync = \u0026#34;1MB\u0026#34; segment_size = \u0026#34;16MB\u0026#34; arena_size = \u0026#34;4MB\u0026#34; wal_fsync_interval = \u0026#34;1s\u0026#34; ## WAL cleanup (prevents disk exhaustion) [storage_config.wal_cleanup_config] enabled = true interval = \u0026#34;5m\u0026#34; max_age = \u0026#34;1h\u0026#34; min_segments = 5 max_segments = 100 ## Write notification coalescing [write_notify_config] enabled = true max_delay = \u0026#34;20ms\u0026#34; ## ZeroMQ notifications (optional - for local apps) [notifier_config.default] bind_port = 5555 high_water_mark = 1000 linger_time = 1000 [notifier_config.users] bind_port = 5556 high_water_mark = 1000 linger_time = 1000 ## Profiling endpoint [pprof_config] enabled = true port = 6060 ## Logging [log_config] log_level = \u0026#34;info\u0026#34; [log_config.min_level_percents] debug = 100.0 info = 100.0 warn = 100.0 error = 100.03. Start the Server# Server Mode (using replicator command):\n./unisondb --config server.toml replicatorYou can also put the command before flags:\n./unisondb replicator --config server.toml4. Verify Server is Running# Check HTTP health endpoint:\ncurl http://localhost:4000/healthDevelopment Mode (Insecure)# For quick local testing without TLS:\nserver-dev.toml:\nhttp_port = 4000 [grpc_config] port = 4001 allow_insecure = true # WARNING: Development only! [storage_config] base_dir = \u0026#34;./data/server\u0026#34; namespaces = [\u0026#34;default\u0026#34;] [log_config] log_level = \u0026#34;debug\u0026#34;./unisondb --config server-dev.toml replicatorRunning in Relayer Mode# Relayer Mode runs UnisonDB as a replica that streams changes from an upstream server.\n1. Create Relayer Configuration# Create a relayer.toml configuration file:\n## HTTP API port (different from server) http_port = 5000 listen_ip = \u0026#34;0.0.0.0\u0026#34; ## gRPC config (can accept downstream relayers) [grpc_config] listen_ip = \u0026#34;0.0.0.0\u0026#34; port = 5001 cert_path = \u0026#34;./certs/server.crt\u0026#34; key_path = \u0026#34;./certs/server.key\u0026#34; ca_path = \u0026#34;./certs/ca.crt\u0026#34; ## Storage configuration [storage_config] base_dir = \u0026#34;./data/relayer\u0026#34; namespaces = [\u0026#34;default\u0026#34;, \u0026#34;users\u0026#34;, \u0026#34;products\u0026#34;] bytes_per_sync = \u0026#34;1MB\u0026#34; # IMPORTANT: segment_size MUST match upstream server! segment_size = \u0026#34;16MB\u0026#34; arena_size = \u0026#34;4MB\u0026#34; ## Relayer configuration - connects to upstream [relayer_config.primary] namespaces = [\u0026#34;default\u0026#34;, \u0026#34;users\u0026#34;, \u0026#34;products\u0026#34;] cert_path = \u0026#34;./certs/client.crt\u0026#34; key_path = \u0026#34;./certs/client.key\u0026#34; ca_path = \u0026#34;./certs/ca.crt\u0026#34; upstream_address = \u0026#34;localhost:4001\u0026#34; segment_lag_threshold = 100 allow_insecure = false ## Optional: Connect to multiple upstreams # [relayer_config.secondary] # namespaces = [\u0026#34;products\u0026#34;] # upstream_address = \u0026#34;other-server:4001\u0026#34; # cert_path = \u0026#34;./certs/client.crt\u0026#34; # key_path = \u0026#34;./certs/client.key\u0026#34; # ca_path = \u0026#34;./certs/ca.crt\u0026#34; ## ZeroMQ notifications (optional) [notifier_config.default] bind_port = 6555 high_water_mark = 1000 linger_time = 1000 ## Logging [log_config] log_level = \u0026#34;info\u0026#34; [log_config.min_level_percents] debug = 1.0 # Sample 1% of debug logs info = 10.0 # Sample 10% of info logs warn = 100.0 error = 100.02. Start the Relayer# Start relayer:\n./unisondb --config relayer.toml relayer3. Enable gRPC Server on Relayer (Multi-Hop)# To allow downstream relayers to connect to this relayer:\n./unisondb --config relayer.toml --grpc relayerThis enables the relayer to act as both a consumer (from upstream) and a producer (to downstream).\nDevelopment Mode (Insecure)# relayer-dev.toml:\nhttp_port = 5000 [grpc_config] port = 5001 [storage_config] base_dir = \u0026#34;./data/relayer\u0026#34; namespaces = [\u0026#34;default\u0026#34;] segment_size = \u0026#34;16MB\u0026#34; # Must match server! [relayer_config.primary] namespaces = [\u0026#34;default\u0026#34;] upstream_address = \u0026#34;localhost:4001\u0026#34; allow_insecure = true # WARNING: Development only! segment_lag_threshold = 100 [log_config] log_level = \u0026#34;debug\u0026#34;./unisondb --config relayer-dev.toml relayerBasic Operations# Writing Data# Key-Value Write (via HTTP):\n# Put a key-value pair curl -X POST http://localhost:4000/api/v1/namespaces/default/kv \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;key\u0026#34;: \u0026#34;user:123\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;eyJuYW1lIjoiQWxpY2UiLCJlbWFpbCI6ImFsaWNlQGV4YW1wbGUuY29tIn0=\u0026#34; }\u0026#39;Batch Write:\ncurl -X POST http://localhost:4000/api/v1/namespaces/default/kv/batch \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;operations\u0026#34;: [ {\u0026#34;key\u0026#34;: \u0026#34;user:1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;...\u0026#34;}, {\u0026#34;key\u0026#34;: \u0026#34;user:2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;...\u0026#34;}, {\u0026#34;key\u0026#34;: \u0026#34;user:3\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;...\u0026#34;} ] }\u0026#39;Reading Data# Read from Server:\ncurl http://localhost:4000/api/v1/namespaces/default/kv/user:123Read from Relayer (same API):\ncurl http://localhost:5000/api/v1/namespaces/default/kv/user:123Subscribing to Changes (ZeroMQ)# Python example (install pyzmq first):\nimport zmq context = zmq.Context() socket = context.socket(zmq.SUB) # Subscribe to \u0026#39;default\u0026#39; namespace socket.connect(\u0026#34;tcp://localhost:5555\u0026#34;) socket.setsockopt(zmq.SUBSCRIBE, b\u0026#34;\u0026#34;) # Subscribe to all messages print(\u0026#34;Listening for changes on namespace \u0026#39;default\u0026#39;...\u0026#34;) while True: message = socket.recv() print(f\u0026#34;Change notification: {message}\u0026#34;)Run the subscriber:\npython subscriber.pyNow any writes to the default namespace will trigger notifications!\nCommon Deployment Patterns# 1. Single Server (Development)# # Terminal 1: Start server ./unisondb --config server-dev.toml replicator2. Server + Single Relayer (Read Scaling)# # Terminal 1: Start server ./unisondb --config server.toml replicator # Terminal 2: Start relayer ./unisondb --config relayer.toml relayer3. Server + Multiple Relayers (Edge Computing)# # Terminal 1: Start server ./unisondb --config server.toml replicator # Terminal 2: Start relayer 1 ./unisondb --config relayer1.toml relayer # Terminal 3: Start relayer 2 ./unisondb --config relayer2.toml relayer # Terminal 4: Start relayer 3 ./unisondb --config relayer3.toml relayer4. Multi-Hop (Relayer → Relayer)# # Terminal 1: Primary server ./unisondb --config server.toml replicator # Terminal 2: L1 relayer (with gRPC enabled for downstream) ./unisondb --config relayer-l1.toml --grpc relayer # Terminal 3: L2 relayer (connects to L1) # Update relayer-l2.toml upstream_address to point to L1 (localhost:5001) ./unisondb --config relayer-l2.toml relayerHappy building with UnisonDB!\n"},{"id":2,"href":"/docs/api/http-api/","title":"HTTP API Reference","section":"API Reference","content":"HTTP API Reference# Complete reference for UnisonDB\u0026rsquo;s HTTP REST API.\nBase URL# http://localhost:4000/api/v1/{namespace}Data Encoding# All binary values must be base64-encoded:\n# Encode a value echo -n \u0026#34;hello world\u0026#34; | base64 # Output: aGVsbG8gd29ybGQ= # Use in request curl -X PUT http://localhost:4000/api/v1/default/kv/greeting \\ -d \u0026#39;{\u0026#34;value\u0026#34;:\u0026#34;aGVsbG8gd29ybGQ=\u0026#34;}\u0026#39;Key-Value Operations# Put KV# Store a key-value pair.\nRequest:\nPUT /api/v1/{namespace}/kv/{key} Content-Type: application/json { \u0026#34;value\u0026#34;: \u0026#34;base64-encoded-value\u0026#34; }Example:\ncurl -X PUT http://localhost:4000/api/v1/default/kv/user:123 \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;value\u0026#34;: \u0026#34;eyJuYW1lIjoiSm9obiIsImFnZSI6MzB9\u0026#34; }\u0026#39;Response (200 OK):\n{ \u0026#34;success\u0026#34;: true }Errors:\n400 Bad Request: Invalid base64 encoding 404 Not Found: Namespace not found 500 Internal Server Error: Engine error Get KV# Retrieve a value by key.\nRequest:\nGET /api/v1/{namespace}/kv/{key}Example:\ncurl http://localhost:4000/api/v1/default/kv/user:123Response (200 OK):\n{ \u0026#34;value\u0026#34;: \u0026#34;eyJuYW1lIjoiSm9obiIsImFnZSI6MzB9\u0026#34;, \u0026#34;found\u0026#34;: true }Response (404 Not Found):\n{ \u0026#34;value\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;found\u0026#34;: false } Delete KV# Delete a key.\nRequest:\nDELETE /api/v1/{namespace}/kv/{key}Example:\ncurl -X DELETE http://localhost:4000/api/v1/default/kv/user:123Response (200 OK):\n{ \u0026#34;success\u0026#34;: true } Batch KV Operations# Perform multiple operations in one request.\nBatch Put# Request:\nPOST /api/v1/{namespace}/kv/batch Content-Type: application/json { \u0026#34;operation\u0026#34;: \u0026#34;put\u0026#34;, \u0026#34;items\u0026#34;: [ {\u0026#34;key\u0026#34;: \u0026#34;key1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dmFsdWUx\u0026#34;}, {\u0026#34;key\u0026#34;: \u0026#34;key2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dmFsdWUy\u0026#34;} ] }Example:\ncurl -X POST http://localhost:4000/api/v1/default/kv/batch \\ -d \u0026#39;{ \u0026#34;operation\u0026#34;: \u0026#34;put\u0026#34;, \u0026#34;items\u0026#34;: [ {\u0026#34;key\u0026#34;: \u0026#34;user:1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dXNlcjE=\u0026#34;}, {\u0026#34;key\u0026#34;: \u0026#34;user:2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dXNlcjI=\u0026#34;} ] }\u0026#39;Response (200 OK):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;processed\u0026#34;: 2 }Batch Get# Request:\nPOST /api/v1/{namespace}/kv/batch Content-Type: application/json { \u0026#34;operation\u0026#34;: \u0026#34;get\u0026#34;, \u0026#34;keys\u0026#34;: [\u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;] }Response (200 OK):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;items\u0026#34;: [ {\u0026#34;key\u0026#34;: \u0026#34;key1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;dmFsdWUx\u0026#34;, \u0026#34;found\u0026#34;: true}, {\u0026#34;key\u0026#34;: \u0026#34;key2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;found\u0026#34;: false} ] }Batch Delete# Request:\nPOST /api/v1/{namespace}/kv/batch Content-Type: application/json { \u0026#34;operation\u0026#34;: \u0026#34;delete\u0026#34;, \u0026#34;keys\u0026#34;: [\u0026#34;key1\u0026#34;, \u0026#34;key2\u0026#34;] }Response (200 OK):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;processed\u0026#34;: 2 } Wide-Column Operations# Put Row# Store a row with multiple columns.\nRequest:\nPUT /api/v1/{namespace}/row/{rowKey} Content-Type: application/json { \u0026#34;columns\u0026#34;: { \u0026#34;column1\u0026#34;: \u0026#34;base64-value1\u0026#34;, \u0026#34;column2\u0026#34;: \u0026#34;base64-value2\u0026#34; } }Example:\ncurl -X PUT http://localhost:4000/api/v1/default/row/user:john \\ -d \u0026#39;{ \u0026#34;columns\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Sm9obiBEb2U=\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;am9obkBleGFtcGxlLmNvbQ==\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;MzA=\u0026#34; } }\u0026#39;Response (200 OK):\n{ \u0026#34;success\u0026#34;: true } Get Row# Retrieve all columns for a row.\nRequest:\nGET /api/v1/{namespace}/row/{rowKey}Example:\ncurl http://localhost:4000/api/v1/default/row/user:johnResponse (200 OK):\n{ \u0026#34;rowKey\u0026#34;: \u0026#34;user:john\u0026#34;, \u0026#34;columns\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Sm9obiBEb2U=\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;am9obkBleGFtcGxlLmNvbQ==\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;MzA=\u0026#34; }, \u0026#34;found\u0026#34;: true } Get Row Columns# Retrieve specific columns only.\nRequest:\nGET /api/v1/{namespace}/row/{rowKey}?columns=col1,col2Example:\ncurl \u0026#34;http://localhost:4000/api/v1/default/row/user:john?columns=name,email\u0026#34;Response (200 OK):\n{ \u0026#34;rowKey\u0026#34;: \u0026#34;user:john\u0026#34;, \u0026#34;columns\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Sm9obiBEb2U=\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;am9obkBleGFtcGxlLmNvbQ==\u0026#34; }, \u0026#34;found\u0026#34;: true } Delete Row# Delete an entire row.\nRequest:\nDELETE /api/v1/{namespace}/row/{rowKey}Example:\ncurl -X DELETE http://localhost:4000/api/v1/default/row/user:johnResponse (200 OK):\n{ \u0026#34;success\u0026#34;: true } Delete Row Columns# Delete specific columns from a row.\nRequest:\nDELETE /api/v1/{namespace}/row/{rowKey}/columns?columns=col1,col2Example:\ncurl -X DELETE \u0026#34;http://localhost:4000/api/v1/default/row/user:john/columns?columns=age,city\u0026#34;Response (200 OK):\n{ \u0026#34;success\u0026#34;: true } Batch Row Operations# Batch Put Rows# Request:\nPOST /api/v1/{namespace}/row/batch Content-Type: application/json { \u0026#34;operation\u0026#34;: \u0026#34;put\u0026#34;, \u0026#34;rows\u0026#34;: [ { \u0026#34;rowKey\u0026#34;: \u0026#34;user:1\u0026#34;, \u0026#34;columns\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;QWxpY2U=\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;YWxpY2VAZXhhbXBsZS5jb20=\u0026#34; } } ] }Response (200 OK):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;processed\u0026#34;: 1 }Batch Get Rows# Request:\nPOST /api/v1/{namespace}/row/batch Content-Type: application/json { \u0026#34;operation\u0026#34;: \u0026#34;get\u0026#34;, \u0026#34;rowKeys\u0026#34;: [\u0026#34;user:1\u0026#34;, \u0026#34;user:2\u0026#34;] }Response (200 OK):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;rows\u0026#34;: [ { \u0026#34;rowKey\u0026#34;: \u0026#34;user:1\u0026#34;, \u0026#34;columns\u0026#34;: {\u0026#34;name\u0026#34;: \u0026#34;QWxpY2U=\u0026#34;}, \u0026#34;found\u0026#34;: true }, { \u0026#34;rowKey\u0026#34;: \u0026#34;user:2\u0026#34;, \u0026#34;columns\u0026#34;: {}, \u0026#34;found\u0026#34;: false } ] } Large Object (LOB) Operations# Put LOB# Upload a large binary object. Check Transaction API.\nGet LOB# Download a large binary object.\nRequest:\nGET /api/v1/{namespace}/lob?key={key}Example:\ncurl \u0026#34;http://localhost:4000/api/v1/default/lob?key=file:doc.pdf\u0026#34; \\ --output document.pdfResponse: Binary data stream\nTransaction Operations# Transactions allow atomic operations across multiple keys.\nTransaction Lifecycle# 1. BEGIN → Get transaction ID 2. APPEND → Add operations (multiple times) 3. COMMIT → Apply atomically OR 3. ABORT → Cancel transactionBegin Transaction# Start a new transaction.\nRequest:\nPOST /api/v1/{namespace}/tx/begin Content-Type: application/json { \u0026#34;operation\u0026#34;: \u0026#34;put\u0026#34;, \u0026#34;entryType\u0026#34;: \u0026#34;kv\u0026#34; }Parameters:\noperation: \u0026quot;put\u0026quot;, \u0026quot;update\u0026quot;, or \u0026quot;delete\u0026quot; entryType: \u0026quot;kv\u0026quot;, \u0026quot;row\u0026quot;, or \u0026quot;lob\u0026quot; Example:\ncurl -X POST http://localhost:4000/api/v1/default/tx/begin \\ -d \u0026#39;{ \u0026#34;operation\u0026#34;: \u0026#34;put\u0026#34;, \u0026#34;entryType\u0026#34;: \u0026#34;kv\u0026#34; }\u0026#39;Response (200 OK):\n{ \u0026#34;txnId\u0026#34;: \u0026#34;2a3b4c5d6e7f8g9h0i1j2k3l4m5n6o7p\u0026#34;, \u0026#34;success\u0026#34;: true }Save the txnId - you\u0026rsquo;ll need it for subsequent requests!\nAppend KV to Transaction# Add a key-value operation to the transaction.\nRequest:\nPOST /api/v1/{namespace}/tx/{txnId}/kv Content-Type: application/json { \u0026#34;key\u0026#34;: \u0026#34;mykey\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;bXl2YWx1ZQ==\u0026#34; }Example:\n# Use the txnId from BEGIN response curl -X POST http://localhost:4000/api/v1/default/tx/2a3b4c.../kv \\ -d \u0026#39;{ \u0026#34;key\u0026#34;: \u0026#34;account:alice\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;MTAwMA==\u0026#34; }\u0026#39;Response (200 OK):\n{ \u0026#34;success\u0026#34;: true }Call this endpoint multiple times to add multiple operations to the same transaction.\nAppend Row to Transaction# Add a row operation to the transaction.\nRequest:\nPOST /api/v1/{namespace}/tx/{txnId}/row Content-Type: application/json { \u0026#34;rowKey\u0026#34;: \u0026#34;user:1\u0026#34;, \u0026#34;columns\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;QWxpY2U=\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;YWN0aXZl\u0026#34; } }Example:\ncurl -X POST http://localhost:4000/api/v1/default/tx/{txnId}/row \\ -d \u0026#39;{ \u0026#34;rowKey\u0026#34;: \u0026#34;user:charlie\u0026#34;, \u0026#34;columns\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Q2hhcmxpZQ==\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;Y2hhcmxpZUBleGFtcGxlLmNvbQ==\u0026#34; } }\u0026#39;Response (200 OK):\n{ \u0026#34;success\u0026#34;: true } Append LOB to Transaction# Add a large object to the transaction.\nRequest:\nPOST /api/v1/{namespace}/tx/{txnId}/lob?key={key} Content-Type: application/octet-stream \u0026lt;binary data\u0026gt;Example:\ncurl -X POST \u0026#34;http://localhost:4000/api/v1/default/tx/{txnId}/lob?key=file:backup.tar.gz\u0026#34; \\ --data-binary @backup.tar.gzResponse (200 OK):\n{ \u0026#34;success\u0026#34;: true } Commit Transaction# Apply all operations atomically.\nRequest:\nPOST /api/v1/{namespace}/tx/{txnId}/commitExample:\ncurl -X POST http://localhost:4000/api/v1/default/tx/2a3b4c.../commitResponse (200 OK):\n{ \u0026#34;success\u0026#34;: true }After commit:\nAll operations are applied atomically Transaction ID is no longer valid Data is durable and replicated Abort Transaction# Cancel the transaction without applying changes.\nRequest:\nPOST /api/v1/{namespace}/tx/{txnId}/abortExample:\ncurl -X POST http://localhost:4000/api/v1/default/tx/2a3b4c.../abortResponse (200 OK):\n{ \u0026#34;success\u0026#34;: true }After abort:\nNo operations are applied Transaction ID is no longer valid All buffered changes are discarded Metadata Operations# Get Current Offset# Get the current WAL position.\nRequest:\nGET /api/v1/{namespace}/offsetExample:\ncurl http://localhost:4000/api/v1/default/offsetResponse (200 OK):\n{ \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;segmentId\u0026#34;: 5, \u0026#34;offset\u0026#34;: 12345 } Get Engine Statistics# Get engine performance statistics.\nRequest:\nGET /api/v1/{namespace}/statsExample:\ncurl http://localhost:4000/api/v1/default/statsResponse (200 OK):\n{ \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;opsReceived\u0026#34;: 15234, \u0026#34;opsFlushed\u0026#34;: 15100, \u0026#34;currentSegment\u0026#34;: 5, \u0026#34;currentOffset\u0026#34;: 12345, \u0026#34;lastFlushTime\u0026#34;: \u0026#34;2024-01-15T10:30:45Z\u0026#34; } Get Checkpoint# Get the last checkpoint position.\nRequest:\nGET /api/v1/{namespace}/checkpointExample:\ncurl http://localhost:4000/api/v1/default/checkpointResponse (200 OK):\n{ \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;recordProcessed\u0026#34;: 15000, \u0026#34;segmentId\u0026#34;: 5, \u0026#34;offset\u0026#34;: 12000 } Error Responses# All errors follow this format:\n{ \u0026#34;error\u0026#34;: \u0026#34;error message description\u0026#34; }HTTP Status Codes# Code Meaning Example 200 Success Operation completed 400 Bad Request Invalid base64, malformed JSON 404 Not Found Namespace not found, key not found, transaction not found 500 Internal Server Error Engine error, disk full, WAL error Common Errors# Namespace not found:\n{ \u0026#34;error\u0026#34;: \u0026#34;namespace not found: invalid-ns\u0026#34; }Status: 404 Not Found\nTransaction not found:\n{ \u0026#34;error\u0026#34;: \u0026#34;transaction not found: 2a3b4c5d...\u0026#34; }Status: 404 Not Found\nInvalid base64:\n{ \u0026#34;error\u0026#34;: \u0026#34;invalid base64 encoding\u0026#34; }Status: 400 Bad Request\nEngine error:\n{ \u0026#34;error\u0026#34;: \u0026#34;failed to write: disk full\u0026#34; }Status: 500 Internal Server Error\nComplete Transaction Example# #!/bin/bash # 1. Begin transaction RESPONSE=$(curl -s -X POST http://localhost:4000/api/v1/default/tx/begin \\ -d \u0026#39;{\u0026#34;operation\u0026#34;:\u0026#34;put\u0026#34;,\u0026#34;entryType\u0026#34;:\u0026#34;kv\u0026#34;}\u0026#39;) TXN_ID=$(echo $RESPONSE | jq -r \u0026#39;.txnId\u0026#39;) echo \u0026#34;Transaction ID: $TXN_ID\u0026#34; # 2. Append multiple operations curl -X POST http://localhost:4000/api/v1/default/tx/$TXN_ID/kv \\ -d \u0026#39;{\u0026#34;key\u0026#34;:\u0026#34;account:alice:balance\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;MTAwMA==\u0026#34;}\u0026#39; curl -X POST http://localhost:4000/api/v1/default/tx/$TXN_ID/kv \\ -d \u0026#39;{\u0026#34;key\u0026#34;:\u0026#34;account:bob:balance\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;MjAwMA==\u0026#34;}\u0026#39; curl -X POST http://localhost:4000/api/v1/default/tx/$TXN_ID/kv \\ -d \u0026#39;{\u0026#34;key\u0026#34;:\u0026#34;transfer:log:123\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;YWxpY2UgLT4gYm9iOiAxMDA=\u0026#34;}\u0026#39; # 3. Commit curl -X POST http://localhost:4000/api/v1/default/tx/$TXN_ID/commit echo \u0026#34;Transaction committed!\u0026#34; # 4. Verify curl http://localhost:4000/api/v1/default/kv/account:alice:balance "},{"id":3,"href":"/docs/architecture/","title":"Architecture","section":"Documentation","content":"Architecture Overview# UnisonDB is a log-native database that replicates like a message bus. It combines transactional database semantics with streaming replication mechanics, designed for edge computing, local-first applications, and distributed topologies.\nKey Characteristics# Aspect Design Choice Storage Model Multi-modal: Key-Value, Wide-Column, Large Objects (LOB) Storage Engine B+Tree (LMDB/BoltDB) with in-memory MemTable overlay Replication Log streaming (gRPC) with eventual consistency Local Events ZeroMQ PUB/SUB for interprocess notifications Consistency Single-primary writes, eventual consistency for replicas Durability WAL-first with configurable fsync Deployment Modes Server (writable primary) \u0026amp; Relayer (read-only replica) Core Concepts# 1. Log-Native Design# The Write-Ahead Log (WAL) is a first-class citizen, not just a recovery mechanism.\nImplications:\nReplication = Log streaming: No separate replication protocol Recovery = Log replay: State reconstructed from WAL Time-travel enabled: Historic snapshots from log Single source of truth: All operations flow through WAL 2. Operational Modes# UnisonDB instances run in one of two modes:\nServer Mode (Primary)# Writable instance that maintains the authoritative WAL.\n┌─────────────────────────────────────┐ │ Server Mode Instance │ │ │ │ • Accepts writes (HTTP/gRPC API) │ │ • Maintains authoritative WAL │ │ • Streams to relayers (gRPC) │ │ • Publishes local events (ZeroMQ) │ │ • Serves reads from local storage │ └─────────────────────────────────────┘Relayer Mode (Replica)# Read-only instance that streams changes from upstream servers.\n┌─────────────────────────────────────┐ │ Relayer Mode Instance │ │ │ │ • Connects to upstream (gRPC) │ │ • Receives WAL segment streams │ │ • Applies to local storage (RO) │ │ • Can relay to downstream nodes │ │ • Publishes local events (ZeroMQ) │ │ • Serves reads (data locality) │ └─────────────────────────────────────┘3. Dual Communication Channels# UnisonDB separates distribution from local reactivity:\nChannel Purpose Use Case Scope gRPC Durable replication Node-to-node WAL streaming Network (cross-machine) ZeroMQ Event notifications Local application reactivity IPC (same machine) Design Rationale:\ngRPC: Network-tolerant, authenticated, handles failures, durability guarantees ZeroMQ: Zero-copy IPC, microsecond latency, fire-and-forget, local-only System Architecture# ┌────────────────────────────────────────────────────────────────────┐ │ UnisonDB Instance │ ├────────────────────────────────────────────────────────────────────┤ │ Client APIs │ │ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ │ │ │ HTTP REST │ │ Transactions │ │ Admin/Stats │ │ │ └──────┬───────┘ └──────┬───────┘ └──────┬───────┘ │ │ └──────────────────┴──────────────────┘ │ ├────────────────────────────────────────────────────────────────────┤ │ Storage Models │ │ ┌─────────────┐ ┌──────────────┐ ┌──────────────┐ │ │ │ Key-Value │ │ Wide-Column │ │ Large Object │ │ │ └──────┬──────┘ └──────┬───────┘ └──────┬───────┘ │ │ └─────────────────┴──────────────────┘ │ ├────────────────────────────────────────────────────────────────────┤ │ Storage Engine (dbkernel) │ │ │ │ Write: WAL (append) → MemTable → B+Tree (LMDB) │ │ Read: MemTable ⊕ B+Tree → Response │ ├────────────────────────────────────────────────────────────────────┤ │ Distribution Layer │ │ ┌──────────────────────┐ ┌──────────────────────┐ │ │ │ gRPC Replicator │ │ ZeroMQ Notifier │ │ │ │ • WAL streaming │ │ • PUB/SUB events │ │ │ │ • TLS/mTLS │ │ • Per-namespace │ │ │ │ • Bidirectional │ │ • Fire-and-forget │ │ │ └──────────┬───────────┘ └──────────┬───────────┘ │ │ ↓ ↓ │ │ Remote Relayers Local Applications │ └────────────────────────────────────────────────────────────────────┘Core Components# Write-Ahead Log (WAL)# Append-only transaction log that serves as the source of truth.\nProperty Implementation Structure Segmented files (configurable size, default 16MB) Format Binary with CRC32 checksums per entry Lifecycle Write → fsync → MemTable → B+Tree → Segment cleanup Purpose Durability, replication streaming, crash recovery Segment Format:\n┌─────────────────────────────────┐ │ Header (magic, segment#, ts) │ ├─────────────────────────────────┤ │ Entry: [type|ns|key|val|crc] │ │ Entry: [type|ns|key|val|crc] │ │ ... │ └─────────────────────────────────┘Storage Engine# Multi-modal storage built on B+Trees with MemTable overlay.\nComponent Technology Purpose MemTable In-memory hash map Write buffer, recent reads B+Tree LMDB/BoltDB Persistent sorted storage Encoding Model-specific key schemas Namespace isolation Storage Models:\nKey-Value: \u0026lt;key\u0026gt; → \u0026lt;value\u0026gt; Wide-Column: \u0026lt;rowKey\u0026gt;:\u0026lt;colName\u0026gt; → \u0026lt;colValue\u0026gt; Large Object: \u0026lt;objectKey\u0026gt;:chunk:\u0026lt;N\u0026gt; → \u0026lt;chunk_data\u0026gt;Replication System# gRPC-based WAL streaming with bidirectional flow control.\nServer Role (Primary):\nStreams WAL segments to connected relayers Monitors lag per relayer connection Handles backpressure and catch-up requests Relayer Role (Replica):\nConsumes from one or more upstream servers Applies segments in order to local storage Can fan-out to downstream relayers (multi-hop) Guarantees:\nConsistency Model: Eventual (all replicas converge) Delivery: At-least-once with gap detection Ordering: Strict segment sequence enforcement Security: TLS/mTLS (insecure mode for dev only) Change Notifications# ZeroMQ PUB/SUB for local event-driven architectures.\nAspect Detail Scope Per-namespace local IPC (same machine) Pattern One PUB socket → Many SUB sockets Trigger WAL append events Delivery Fire-and-forget, no acknowledgments Config bind_port, high_water_mark, linger_time Example Use Case:\nApplication A writes → UnisonDB appends to WAL → ZeroMQ publishes on tcp://localhost:5555 → Applications B, C, D react to change notificationDesign Principles# Multi-Modal Storage Examples# All storage models share the same WAL and B+Tree, differing only in key encoding:\nModel Example Key Encoding Key-Value user:123 → {\u0026quot;name\u0026quot;:\u0026quot;Alice\u0026quot;} \u0026lt;key\u0026gt; Wide-Column user:123 with columns name, email \u0026lt;rowKey\u0026gt;:\u0026lt;colName\u0026gt; Large Object video:abc as streamable chunks \u0026lt;objectKey\u0026gt;:chunk:\u0026lt;N\u0026gt; Edge-First Topology# Designed for hub-and-spoke, multi-hop replication with data locality:\n┌──────────────┐ │ Primary │ (Server Mode - accepts writes) │ (US-East) │ └──────┬───────┘ │ gRPC ┌────────┼────────┐ ↓ ↓ ↓ ┌───────┐┌───────┐┌───────┐ │Europe ││ Asia ││US-West│ (Relayer Mode - read replicas) │Relayer││Relayer││Relayer│ └───┬───┘└───┬───┘└───┬───┘ │ │ │ ZeroMQ (local IPC) ↓ ↓ ↓ Local Local Local Apps Apps AppsData Flow# Write Path (Server Mode)# Write Request → API Handler → Storage Engine ↓ ┌───────────────┴───────────────┐ ↓ ↓ 1. WAL Append 2. MemTable Update (+ fsync) (in-memory) ↓ ↓ 3. Background Flush ────────────────→ B+Tree (LMDB) ↓ ┌───────┴────────┐ ↓ ↓ gRPC Stream ZeroMQ Publish (to relayers) (to local apps)Latency Profile:\nWAL append + MemTable: \u0026lt; 1ms (sequential write) fsync: ~5-10ms (if enabled) B+Tree flush: Background, async Read Path# Read Request → API Handler → Storage Engine ↓ ┌───────┴───────┐ ↓ ↓ MemTable B+Tree (check first) (if not found) └───────┬───────┘ ↓ Merge \u0026amp; ResponseLatency: \u0026lt; 1ms (local read, no network)\nReplication Flow (gRPC)# Server (Primary) Relayer (Replica) │ │ │ ─── WAL Segment (gRPC stream) ────→ │ │ [metadata + binary + CRC] │ │ ↓ │ 1. Validate checksum │ 2. Append to local WAL │ 3. Apply to MemTable │ 4. Flush to B+Tree │ ↓ │ Can relay downstream │ Can notify local appsNetwork Requirements: TLS/mTLS (production), bidirectional streaming\nNotification Flow (ZeroMQ)# WAL Write → [Coalescer] → ZeroMQ PUB (tcp://localhost:{port}) │ ┌────────────┼────────────┐ ↓ ↓ ↓ App A App B App C (SUB) (SUB) (SUB)Characteristics: Local IPC, fire-and-forget, per-namespace\nStorage Layout# data/ ├── \u0026lt;namespace\u0026gt;/ │ ├── wal/ │ │ ├── segment-00000000 # 16MB segments (configurable) │ │ ├── segment-00000001 │ │ └── ... │ ├── db/ │ │ ├── data.mdb # LMDB data file │ │ └── lock.mdb # LMDB lock file │ └── checkpoint/ │ └── last_applied # Recovery pointPer-Namespace Isolation: Each namespace has independent WAL, DB, and checkpoint state.\nSystem Characteristics# Consistency Model# Aspect Guarantee Writes Single primary (Server Mode) for linearizability Reads Eventually consistent across relayers Replication At-least-once delivery, ordered segments Isolation Per-namespace (independent namespaces) Durability \u0026amp; Recovery# Crash Recovery:\nScan WAL for uncommitted operations Replay WAL to rebuild MemTable and B+Tree Validate checkpoint consistency Resume operations Replication Recovery (Relayer Mode):\nDetermine last applied segment from checkpoint Reconnect to upstream at last offset Request missing segments (gap detection) Apply backlog before serving reads Data Durability:\nWAL with optional fsync (configurable) CRC32 checksums on all WAL entries Segment-level validation during replication Deployment Topologies# 1. Single Server# ┌──────────┐ │ Primary │ (Server Mode) │ + ZeroMQ │ Serves reads \u0026amp; writes └──────────┘ Publishes local eventsUse Case: Small workloads, development, standalone applications\n2. Primary + Read Replicas# ┌──────────┐ │ Primary │ (Server Mode - writes) └────┬─────┘ │ gRPC ┌───────┼───────┐ ↓ ↓ ↓ ┌────────┐┌────────┐┌────────┐ │Relayer ││Relayer ││Relayer │ (Read-only replicas) └────────┘└────────┘└────────┘Use Case: Read-heavy workloads, geographic distribution, high availability\n3. Hub-and-Spoke (Edge Computing)# ┌──────────┐ │ Hub │ (Server Mode) └────┬─────┘ │ gRPC ┌──────────┼──────────┐ ↓ ↓ ↓ ┌──────┐ ┌──────┐ ┌──────┐ │Edge 1│ │Edge 2│ │Edge 3│ (Relayers + ZeroMQ) └──┬───┘ └──┬───┘ └──┬───┘ ↓ ↓ ↓ Local Local Local Apps Apps AppsUse Case: Edge computing, data locality, IoT, retail/branch deployments\n4. Multi-Hop Relay (Deep Edge)# ┌─────────┐ │ Primary │ └────┬────┘ ↓ gRPC ┌─────────┐ │ Tier 1 │ (can relay further) └───┬─────┘ ┌───┴───┐ ↓ ↓ Tier 2 Tier 2 (leaf nodes) ↓ ↓ Apps AppsUse Case: Hierarchical networks, bandwidth-constrained links, CDN-like distribution\n5. Hybrid: Replication + Local Events# ┌────────────────────────┐ │ Primary │ │ ┌──────────────┐ │ │ │ Storage │ │ │ └──┬────────┬──┘ │ │ ↓ ↓ │ │ [gRPC] [ZeroMQ] │ └────┬─────────┬─────────┘ ↓ ↓ Relayers Local Apps (cache, analytics, etc.)Use Case: Microservices architecture with local event-driven components\nTradeoffs \u0026amp; Limitations# Design Tradeoffs# Aspect Tradeoff Rationale Write Scalability Single primary per namespace Ensures linearizable writes, simplifies conflict resolution Read Consistency Eventual consistency on relayers Enables high read scalability and data locality Replication Model At-least-once delivery Prioritizes availability over exactly-once semantics Local Events Fire-and-forget (ZeroMQ) Minimizes latency, tolerates subscriber failures Current Limitations# Write Scaling: Single primary per namespace (no multi-master) Consistency: No strong consistency guarantees for relayer reads Transactions: Limited to single-namespace operations Query Model: No complex queries (no SQL, joins, aggregations) Schema: Schema-less (application-managed structure) When to Use UnisonDB# Good Fit:\nEdge computing with hub-and-spoke topology Read-heavy workloads requiring data locality Event-driven architectures (via ZeroMQ) Applications tolerating eventual consistency Key-value or wide-column access patterns Large object storage with streaming Not a Good Fit:\nStrong consistency requirements across replicas Complex relational queries (joins, aggregations) Multi-region active-active writes Workloads requiring ACID transactions across namespaces Summary# UnisonDB combines database semantics with streaming mechanics through:\nLog-Native Design: WAL as first-class citizen (replication = log streaming) Dual Communication: gRPC for distribution, ZeroMQ for local reactivity Dual Modes: Server (writable primary) and Relayer (read replicas) Multi-Modal Storage: Key-Value, Wide-Column, Large Objects on shared B+Tree Architecture Strengths:\nData locality through edge replicas Event-driven integration via ZeroMQ Simple operational model (log streaming) Flexible deployment topologies (hub-and-spoke, multi-hop) Best For: Edge computing, local-first applications, and read-scalable systems with eventual consistency tolerance.\n"},{"id":4,"href":"/docs/api/","title":"API Reference","section":"Documentation","content":"API Reference# UnisonDB provides API interfaces for client access:\nHTTP REST API # RESTful HTTP API with JSON payloads, supporting:\nKey-Value operations Wide-Column operations Large Object (LOB) operations Stateful transactions Metadata queries Next Steps# HTTP API Reference - Complete HTTP API documentation "},{"id":5,"href":"/docs/getting-started/configurations/","title":"Configuration","section":"Getting Started","content":"Configuration Guide# UnisonDB uses TOML for configuration. This guide covers all available configuration options for both server and relayer modes.\nTable of Contents# Server Mode Relayer Mode Configuration Reference Server Mode# Server mode runs UnisonDB as a primary instance that accepts writes and serves reads. Here\u0026rsquo;s a complete example:\n## Port of the http server http_port = 4000 listen_ip = \u0026#34;0.0.0.0\u0026#34; ## grpc config for replication [grpc_config] listen_ip = \u0026#34;0.0.0.0\u0026#34; port = 4001 # SSL/TLS certificate paths for gRPC server cert_path = \u0026#34;../../certs/server.crt\u0026#34; key_path = \u0026#34;../../certs/server.key\u0026#34; ca_path = \u0026#34;../../certs/ca.crt\u0026#34; # Allow insecure connections (no TLS) - ONLY for development! allow_insecure = false # StorageConfig stores all tunable parameters. [storage_config] base_dir = \u0026#34;/tmp/unisondb/server\u0026#34; # Base directory for storage namespaces = [\u0026#34;default\u0026#34;, \u0026#34;tenant_1\u0026#34;, \u0026#34;tenant_2\u0026#34;, \u0026#34;tenant_3\u0026#34;, \u0026#34;tenant_4\u0026#34;] bytes_per_sync = \u0026#34;1MB\u0026#34; segment_size = \u0026#34;16MB\u0026#34; arena_size = \u0026#34;4MB\u0026#34; wal_fsync_interval = \u0026#34;1s\u0026#34; ## WAL cleanup configuration [storage_config.wal_cleanup_config] enabled = false interval = \u0026#34;5m\u0026#34; max_age = \u0026#34;1h\u0026#34; min_segments = 5 max_segments = 10 ## Write notify config - coalesces notifications from WAL writers to readers [write_notify_config] enabled = true max_delay = \u0026#34;20ms\u0026#34; ## ZeroMQ notifier configuration (per-namespace) ## Publishes change notifications for local application consumption [notifier_config.default] bind_port = 5555 high_water_mark = 1000 linger_time = 1000 [notifier_config.tenant_1] bind_port = 5556 high_water_mark = 1000 linger_time = 1000 [pprof_config] enabled = true port = 6060 [log_config] log_level = \u0026#34;info\u0026#34; disable_timestamp = false ## This is for grpc logging only - controls sampling percentages per level [log_config.min_level_percents] debug = 100.0 info = 50.0 warn = 100.0 error = 100.0 ## Fuzzer configuration (for testing) [fuzz_config] ops_per_namespace = 400 workers_per_namespace = 50 local_relayer_count = 1000 startup_delay = \u0026#34;10s\u0026#34; enable_read_ops = falseRelayer Mode# Relayer mode runs UnisonDB as a replica that streams changes from one or more upstream servers. This provides read scalability and data locality.\n## Port of the http server http_port = 6000 [grpc_config] port = 6001 cert_path = \u0026#34;../../certs/server.crt\u0026#34; key_path = \u0026#34;../../certs/server.key\u0026#34; ca_path = \u0026#34;../../certs/ca.crt\u0026#34; [storage_config] base_dir = \u0026#34;/tmp/unisondb/relayer\u0026#34; namespaces = [\u0026#34;default\u0026#34;, \u0026#34;tenant_1\u0026#34;, \u0026#34;tenant_2\u0026#34;] bytes_per_sync = \u0026#34;1MB\u0026#34; ## IMPORTANT: segment_size must match upstream server! segment_size = \u0026#34;16MB\u0026#34; arena_size = \u0026#34;4MB\u0026#34; ## Relayer configuration - can have multiple upstreams [relayer_config] [relayer_config.relayer1] namespaces = [\u0026#34;default\u0026#34;, \u0026#34;tenant_1\u0026#34;, \u0026#34;tenant_2\u0026#34;] cert_path = \u0026#34;../../certs/client.crt\u0026#34; key_path = \u0026#34;../../certs/client.key\u0026#34; ca_path = \u0026#34;../../certs/ca.crt\u0026#34; upstream_address = \u0026#34;localhost:4001\u0026#34; segment_lag_threshold = 100 allow_insecure = false # Optional: custom gRPC service config JSON grpc_service_config = \u0026#34;\u0026#34; ## Optional: Add more relayers for different upstream sources [relayer_config.relayer2] namespaces = [\u0026#34;tenant_3\u0026#34;] cert_path = \u0026#34;../../certs/client2.crt\u0026#34; key_path = \u0026#34;../../certs/client2.key\u0026#34; ca_path = \u0026#34;../../certs/ca.crt\u0026#34; upstream_address = \u0026#34;remote-server:4001\u0026#34; segment_lag_threshold = 100 [log_config] log_level = \u0026#34;info\u0026#34; [log_config.min_level_percents] debug = 0.01 info = 1.0 warn = 1.0 error = 1.0 Configuration Reference# Server Configuration# HTTP Server# http_port = 4000 listen_ip = \u0026#34;0.0.0.0\u0026#34;http_port# Type: Integer Default: 4000 Description: Port for the HTTP API server listen_ip# Type: String Default: \u0026quot;0.0.0.0\u0026quot; Description: IP address to bind HTTP server to Note: Use \u0026quot;127.0.0.1\u0026quot; for localhost-only access gRPC Configuration# [grpc_config] listen_ip = \u0026#34;0.0.0.0\u0026#34; port = 4001 cert_path = \u0026#34;/path/to/server.crt\u0026#34; key_path = \u0026#34;/path/to/server.key\u0026#34; ca_path = \u0026#34;/path/to/ca.crt\u0026#34; allow_insecure = falselisten_ip# Type: String Default: \u0026quot;0.0.0.0\u0026quot; Description: IP address to bind gRPC server to port# Type: Integer Default: 4001 Description: Port for the gRPC server (used for replication) cert_path# Type: String Default: \u0026quot;\u0026quot; Description: Path to TLS certificate file (PEM format) Required: Yes (unless allow_insecure = true) key_path# Type: String Default: \u0026quot;\u0026quot; Description: Path to TLS private key file (PEM format) Required: Yes (unless allow_insecure = true) ca_path# Type: String Default: \u0026quot;\u0026quot; Description: Path to CA certificate file for mTLS Required: Yes (unless allow_insecure = true) allow_insecure# Type: Boolean Default: false Description: Allow insecure connections without TLS Warning: ONLY use in development! Always enable TLS in production Storage Configuration# [storage_config] base_dir = \u0026#34;./data\u0026#34; namespaces = [\u0026#34;default\u0026#34;, \u0026#34;app\u0026#34;] bytes_per_sync = \u0026#34;1MB\u0026#34; segment_size = \u0026#34;16MB\u0026#34; arena_size = \u0026#34;4MB\u0026#34; wal_fsync_interval = \u0026#34;1s\u0026#34; disable_entry_type_check = falsebase_dir# Type: String Default: \u0026quot;./data\u0026quot; Description: Base directory for all data files (WAL segments, LMDB) Note: Must have write permissions namespaces# Type: Array of Strings Default: [\u0026quot;default\u0026quot;] Description: List of namespaces to create on startup Example: [\u0026quot;default\u0026quot;, \u0026quot;users\u0026quot;, \u0026quot;metrics\u0026quot;, \u0026quot;logs\u0026quot;] Note: Each namespace is isolated with separate WAL and storage bytes_per_sync# Type: String (with unit) Default: \u0026quot;1MB\u0026quot; Valid Units: KB, MB, GB Description: Number of bytes to write before forcing fsync segment_size# Type: String (with unit) Default: \u0026quot;16MB\u0026quot; Valid Units: KB, MB, GB Range: 1MB to 1GB Description: Size of each WAL segment file Important: Must match across server and relayer! arena_size# Type: String (with unit) Default: \u0026quot;4MB\u0026quot; Valid Units: KB, MB, GB Range: 1MB to 64MB Description: Size of the write buffer (memtable) Performance: Larger = fewer flushes, more memory usage wal_fsync_interval# Type: String (duration) Default: \u0026quot;1s\u0026quot; Valid Units: ms, s, m Description: Interval for periodic WAL fsync Trade-off: Lower = better durability, higher = better performance WAL Cleanup Configuration# [storage_config.wal_cleanup_config] enabled = false interval = \u0026#34;5m\u0026#34; max_age = \u0026#34;1h\u0026#34; min_segments = 5 max_segments = 10enabled# Type: Boolean Default: false Description: Enable automatic WAL segment cleanup interval# Type: String (duration) Default: \u0026quot;5m\u0026quot; Description: How often to run cleanup max_age# Type: String (duration) Default: \u0026quot;1h\u0026quot; Description: Maximum age of segments before cleanup min_segments# Type: Integer Default: 5 Description: Minimum number of segments to keep max_segments# Type: Integer Default: 10 Description: Trigger cleanup when this many segments exist Write Notification Configuration# Write notifications coalesce updates from WAL writers to readers, reducing notification overhead.\n[write_notify_config] enabled = true max_delay = \u0026#34;20ms\u0026#34;enabled# Type: Boolean Default: true Description: Enable write notification coalescing max_delay# Type: String (duration) Default: \u0026quot;20ms\u0026quot; Valid Units: ms, s Description: Maximum delay before notifying readers Trade-off: Higher = better batching, higher latency for reads ZeroMQ Notifier Configuration# UnisonDB can publish change notifications via ZeroMQ PUB/SUB sockets. This allows local applications to subscribe to real-time change notifications for specific namespaces.\nUse Case: Applications running on the same machine can subscribe to a namespace\u0026rsquo;s ZeroMQ socket and receive notifications whenever data changes, enabling reactive architectures.\n## Each namespace can have its own ZeroMQ notifier [notifier_config.default] bind_port = 5555 high_water_mark = 1000 linger_time = 1000 [notifier_config.tenant_1] bind_port = 5556 high_water_mark = 2000 linger_time = 500bind_port# Type: Integer Required: Yes Description: Port to bind ZeroMQ PUB socket to Format: Applications subscribe to tcp://localhost:{bind_port} high_water_mark# Type: Integer Default: 1000 Description: Maximum number of queued messages before blocking Note: Higher values use more memory but reduce message loss linger_time# Type: Integer (milliseconds) Default: 1000 Description: How long to wait for pending messages on shutdown Range: 0 to 5000 ms Example Application Subscription:\nimport zmq context = zmq.Context() socket = context.socket(zmq.SUB) socket.connect(\u0026#34;tcp://localhost:5555\u0026#34;) # Connect to default namespace socket.setsockopt(zmq.SUBSCRIBE, b\u0026#34;\u0026#34;) # Subscribe to all messages while True: message = socket.recv() print(f\u0026#34;Received change notification: {message}\u0026#34;) Relayer Configuration# Relayer configuration allows a UnisonDB instance to stream WAL changes from one or more upstream servers. This is useful for:\nRead scaling: Run multiple read replicas Data locality: Keep data close to consumers in different regions Backup: Maintain hot standbys [relayer_config] [relayer_config.relayer1] namespaces = [\u0026#34;default\u0026#34;, \u0026#34;tenant_1\u0026#34;] cert_path = \u0026#34;../../certs/client.crt\u0026#34; key_path = \u0026#34;../../certs/client.key\u0026#34; ca_path = \u0026#34;../../certs/ca.crt\u0026#34; upstream_address = \u0026#34;primary-server:4001\u0026#34; segment_lag_threshold = 100 allow_insecure = false grpc_service_config = \u0026#34;\u0026#34;Map Key (e.g., relayer1)# Type: String Description: Unique identifier for this relayer connection Note: Multiple relayers can be configured with different keys namespaces# Type: Array of Strings Required: Yes Description: List of namespaces to replicate from this upstream Note: Namespaces must exist on both upstream and local instance cert_path# Type: String Description: Path to client TLS certificate for mTLS Required: Yes (unless allow_insecure = true) key_path# Type: String Description: Path to client private key for mTLS Required: Yes (unless allow_insecure = true) ca_path# Type: String Description: Path to CA certificate to verify upstream server Required: Yes (unless allow_insecure = true) upstream_address# Type: String Required: Yes Description: Address of upstream gRPC server Format: host:port (e.g., \u0026quot;localhost:4001\u0026quot;, \u0026quot;10.0.1.5:4001\u0026quot;) segment_lag_threshold# Type: Integer Default: 100 Description: Maximum segment lag before logging warnings Note: Helps monitor replication health allow_insecure# Type: Boolean Default: false Description: Allow insecure connection to upstream (no TLS) Warning: Only for development! grpc_service_config# Type: String (JSON) Default: \u0026quot;\u0026quot; (uses built-in defaults) Description: Custom gRPC service configuration JSON Advanced: See gRPC documentation for format Logging Configuration# [log_config] log_level = \u0026#34;info\u0026#34; disable_timestamp = false [log_config.min_level_percents] debug = 100.0 info = 50.0 warn = 100.0 error = 100.0log_level# Type: String Valid Values: \u0026quot;debug\u0026quot;, \u0026quot;info\u0026quot;, \u0026quot;warn\u0026quot;, \u0026quot;error\u0026quot; Default: \u0026quot;info\u0026quot; Description: Minimum log level to output disable_timestamp# Type: Boolean Default: false Description: Disable timestamps in log output Use Case: When running under systemd/journal (timestamps added automatically) min_level_percents# Type: Map of String to Float Description: Sampling percentages for gRPC logging per level Range: 0.0 to 100.0 Purpose: Reduce log volume in high-traffic scenarios Example: info = 1.0 means sample 1% of info logs Log Levels:\ndebug: 100.0 = log all debug messages info: 50.0 = log 50% of info messages (randomly sampled) warn: 100.0 = log all warnings error: 100.0 = log all errors PProf Configuration# [pprof_config] enabled = true port = 6060enabled# Type: Boolean Default: false Description: Enable pprof HTTP server for profiling port# Type: Integer Default: 6060 Description: Port for pprof HTTP server Access: http://localhost:6060/debug/pprof/ Available Profiles:\n/debug/pprof/heap - Memory allocation /debug/pprof/goroutine - Goroutine stack traces /debug/pprof/profile - CPU profile /debug/pprof/trace - Execution trace Fuzzer Configuration# Built-in fuzzer for testing and stress testing UnisonDB.\n[fuzz_config] ops_per_namespace = 400 workers_per_namespace = 50 local_relayer_count = 1000 startup_delay = \u0026#34;10s\u0026#34; enable_read_ops = falseops_per_namespace# Type: Integer Default: 400 Description: Number of operations to perform per namespace workers_per_namespace# Type: Integer Default: 50 Description: Number of concurrent workers per namespace local_relayer_count# Type: Integer Default: 1000 Description: Number of local relayer goroutines to simulate startup_delay# Type: String (duration) Default: \u0026quot;10s\u0026quot; Description: Delay before starting fuzzer Purpose: Allow infrastructure to fully initialize enable_read_ops# Type: Boolean Default: false Description: Include read operations in fuzzing Note: Generates mixed read/write workload when enabled "},{"id":6,"href":"/docs/examples/","title":"Examples","section":"Documentation","content":"Examples# Explore practical examples that showcase UnisonDB’s capabilities — from single-node setups to multi-datacenter replication and real-time CRDT synchronization.\n1. Building Conflict-Free Multi-Datacenter Systems with CRDTs and UnisonDB # "},{"id":7,"href":"/docs/examples/multi-dc-crdts/","title":"Multi-DC CRDT Replication","section":"Examples","content":"Building Real-Time Multi-Datacenter Applications with CRDTs and Edge Notifications in UnisonDB# Introduction: The Challenge of Distributed State Management# Imagine you\u0026rsquo;re building a globally distributed application where users across different continents need to see consistent data think user presence status, live dashboards, or real-time collaboration features. Traditional databases force you to choose between consistency and availability, but what if there was a better way?\nConflict-free Replicated Data Types (CRDTs) offer a mathematical approach to distributed state management where conflicts are resolved automatically through well-defined merge operations. When combined with edge notifications, you get a powerful pattern: write anywhere, replicate everywhere, and get notified of changes in real-time.\nIn this post, we\u0026rsquo;ll build a multi-datacenter system using UnisonDB that demonstrates:\nConcurrent writes to multiple datacenters Automatic conflict resolution using CRDTs Real-time change notifications via ZeroMQ Eventual consistency across all nodes Architecture Overview# Our demo system consists of three UnisonDB nodes:\n+---------------------------------------------------------------+ | Multi-DC CRDT Architecture | +---------------------------------------------------------------+ Writes Writes | | v v +----------------+ +----------------+ | Datacenter 1 | | Datacenter 2 | | (Primary) | | (Primary) | | | | | | HTTP: 8001 | | HTTP: 8002 | | gRPC: 4001 | | gRPC: 4002 | +--------+-------+ +--------+-------+ | | | gRPC Replication | +---------------------+-------------------+ | v +---------------------+ | Relayer | | (Read-Only) | | | | HTTP: 8003 | | ZMQ dc1: 5555 ---\u0026gt; |----+ | ZMQ dc2: 5556 ---\u0026gt; |----+ Change +---------------------+ | Notifications | v +--------------------+ | CRDT Client | | (Go / Node.js) | | | | Converged State | +--------------------+Component Roles# Component Role Namespace HTTP Port gRPC Port ZMQ Ports DC1 Primary (accepts writes) ad-campaign-dc1 8001 4001 - DC2 Primary (accepts writes) ad-campaign-dc2 8002 4002 - Relayer Read-only replica ad-campaign-dc1, ad-campaign-dc2 8003 - 5555, 5556 Building and Running UnisonDB# Prerequisites# # Ensure you have Go 1.21+ and CGO enabled go version # go version go1.21.0 or higherStep 1: Build UnisonDB# # Clone the repository git clone https://github.com/ankur-anand/unisondb.git cd unisondb # Build the binary (CGO required for RocksDB) CGO_ENABLED=1 go build -o unisondb ./cmd/unisondbStep 2: Start the Multi-DC Cluster# Open three separate terminal windows and run:\nTerminal 1: Start Datacenter 1\n./unisondb -config .cmd/examples/crdt-multi-dc/configs/dc1.toml replicatorTerminal 2: Start Datacenter 2\n./unisondb -config .cmd/examples/crdt-multi-dc/configs/dc2.toml replicatorTerminal 3: Start Relayer\n./unisondb -config .cmd/examples/crdt-multi-dc/configs/relayer.toml relayerYou should see output indicating each node is ready:\nINFO: HTTP server listening on :8001 INFO: gRPC server listening on :4001 INFO: Namespace \u0026#39;ad-campaign-dc1\u0026#39; initializedStep 3: Start the CRDT Client# Open a fourth terminal to run the client that will observe CRDT state:\ncd cmd/examples/golang-crdt-client go run main.goExpected output:\nWaiting for change notifications... Connecting to ZeroMQ ad-campaign-dc1: tcp://localhost:5555 Connecting to ZeroMQ ad-campaign-dc2: tcp://localhost:5556 ZeroMQ listener started for namespace: ad-campaign-dc1 ZeroMQ listener started for namespace: ad-campaign-dc2Your system is now ready!\nUnderstanding CRDTs: Two Types in Action# 1. LWW-Register (Last-Write-Wins Register)# Use Cases: User profiles, configuration settings, feature flags\nHow it works:\nEach write includes a timestamp and replica ID Conflicts are resolved by choosing the write with the latest timestamp If timestamps are equal, the lexicographically higher replica ID wins Data Format:\n{ \u0026#34;value\u0026#34;: \u0026#34;actual data\u0026#34;, \u0026#34;timestamp\u0026#34;: 1698765432000, \u0026#34;replica\u0026#34;: \u0026#34;ad-campaign-dc1\u0026#34; }2. G-Counter (Grow-Only Counter)# Use Cases: Page views, API calls, distributed metrics (monotonically increasing)\nHow it works:\nEach replica maintains its own counter Merging takes the maximum count per replica Total value is the sum of all replica counters Can only increase (never decrease) Data Format:\n{ \u0026#34;replica\u0026#34;: \u0026#34;ad-campaign-dc1\u0026#34;, \u0026#34;count\u0026#34;: 5 }Demo Scenarios with curl Examples# Scenario 1: Basic LWW-Register Update# Let\u0026rsquo;s update a user\u0026rsquo;s status across two datacenters:\nWrite \u0026ldquo;online\u0026rdquo; to DC1 (timestamp: 1698765432000)\ncurl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/lww:user-status\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;value\u0026#34;:\u0026#34;online\u0026#34;,\u0026#34;timestamp\u0026#34;:1698765432000,\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc1\u0026#34;}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;Client Output:\nChange notification received Topic: ad-campaign-dc1.kv Key: lww:user-status Operation: put Processing update: lww:user-status LWW-Register updated: lww:user-status Value: online Timestamp: 1698765432000 Replica: ad-campaign-dc1 CURRENT CRDT STATE LWW-Registers: lww:user-status: Value: online Timestamp: 1698765432000 Replica: ad-campaign-dc1Now write \u0026ldquo;away\u0026rdquo; to DC2 with a newer timestamp:\nWrite \u0026ldquo;away\u0026rdquo; to DC2 (timestamp: 1698765433000)\ncurl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/lww:user-status\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;value\u0026#34;:\u0026#34;away\u0026#34;,\u0026#34;timestamp\u0026#34;:1698765433000,\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc2\u0026#34;}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;Client Output:\nChange notification received Topic: ad-campaign-dc2.kv Key: lww:user-status Operation: put Processing update: lww:user-status LWW-Register updated: lww:user-status Value: away Timestamp: 1698765433000 Replica: ad-campaign-dc2 CURRENT CRDT STATE LWW-Registers: lww:user-status: Value: away Timestamp: 1698765433000 Replica: ad-campaign-dc2What happened? The client automatically resolved the conflict! DC2\u0026rsquo;s write won because it had a newer timestamp (1698765433000 \u0026gt; 1698765432000).\nScenario 2: Concurrent Writes with Same Timestamp# What happens when two datacenters write at the exact same millisecond?\nWrite to DC1:\nTIMESTAMP=$(date +%s)000 curl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/lww:config\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#34;{\\\u0026#34;value\\\u0026#34;:\\\u0026#34;DC1 wins?\\\u0026#34;,\\\u0026#34;timestamp\\\u0026#34;:$TIMESTAMP,\\\u0026#34;replica\\\u0026#34;:\\\u0026#34;ad-campaign-dc1\\\u0026#34;}\u0026#34; | base64)\u0026#39;\u0026#34;}\u0026#39;Write to DC2 (same timestamp):\ncurl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/lww:config\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#34;{\\\u0026#34;value\\\u0026#34;:\\\u0026#34;DC2 wins!\\\u0026#34;,\\\u0026#34;timestamp\\\u0026#34;:$TIMESTAMP,\\\u0026#34;replica\\\u0026#34;:\\\u0026#34;ad-campaign-dc2\\\u0026#34;}\u0026#34; | base64)\u0026#39;\u0026#34;}\u0026#39;Result: ad-campaign-dc2 wins because lexicographically \u0026quot;ad-campaign-dc2\u0026quot; \u0026gt; \u0026quot;ad-campaign-dc1\u0026quot;. This ensures deterministic conflict resolution across all replicas.\nScenario 3: Distributed Counter (G-Counter)# Let\u0026rsquo;s track page views across two datacenters:\nDC1 serves 5 requests:\ncurl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/counter:page-views\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc1\u0026#34;,\u0026#34;count\u0026#34;:5}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;DC2 serves 3 requests:\ncurl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/counter:page-views\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc2\u0026#34;,\u0026#34;count\u0026#34;:3}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;Client Output:\nCURRENT CRDT STATE G-Counters: counter:page-views: Replica Counts: {\u0026#34;ad-campaign-dc1\u0026#34;:5,\u0026#34;ad-campaign-dc2\u0026#34;:3} Total: 8Result: Total = 8 (5 from DC1 + 3 from DC2). The counters from both datacenters are automatically merged!\nScenario 4: Out-of-Order Delivery (Stale Write)# What if network delays cause an old write to arrive after a newer one?\nWrite NEW value to DC1:\ncurl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/lww:feature-flag\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;value\u0026#34;:true,\u0026#34;timestamp\u0026#34;:2000,\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc1\u0026#34;}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;Write OLD value to DC2 (stale):\ncurl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/lww:feature-flag\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;value\u0026#34;:false,\u0026#34;timestamp\u0026#34;:1000,\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc2\u0026#34;}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;Client Output:\nProcessing update: lww:feature-flag LWW-Register ignored (stale): lww:feature-flag Incoming timestamp: 1000 Current timestamp: 2000Result: The stale write is automatically ignored. The CRDT logic ensures we never regress to an older state!\nScenario 5: Multiple Counters Operating Independently# # Track different metrics curl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/counter:api-calls\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc1\u0026#34;,\u0026#34;count\u0026#34;:100}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39; curl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/counter:api-calls\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc2\u0026#34;,\u0026#34;count\u0026#34;:75}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39; curl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/counter:db-queries\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;ad-campaign-dc1\u0026#34;,\u0026#34;count\u0026#34;:250}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39;Client Output:\nCURRENT CRDT STATE G-Counters: counter:api-calls: Replica Counts: {\u0026#34;ad-campaign-dc1\u0026#34;:100,\u0026#34;ad-campaign-dc2\u0026#34;:75} Total: 175 counter:db-queries: Replica Counts: {\u0026#34;ad-campaign-dc1\u0026#34;:250} Total: 250Each counter operates independently with its own convergence!\nReading Data from the Relayer# The relayer provides read-only access to both datacenter namespaces:\nRead from DC1 namespace:\ncurl \u0026#34;http://localhost:8003/api/v1/ad-campaign-dc1/kv/lww:user-status\u0026#34; | jqResponse:\n{ \u0026#34;value\u0026#34;: \u0026#34;eyJ2YWx1ZSI6ImF3YXkiLCJ0aW1lc3RhbXAiOjE2OTg3NjU0MzMwMDAsInJlcGxpY2EiOiJhZC1jYW1wYWlnbi1kYzIifQ==\u0026#34;, \u0026#34;found\u0026#34;: true }Decode the base64 value:\necho \u0026#34;eyJ2YWx1ZSI6ImF3YXkiLCJ0aW1lc3RhbXAiOjE2OTg3NjU0MzMwMDAsInJlcGxpY2EiOiJhZC1jYW1wYWlnbi1kYzIifQ==\u0026#34; | base64 -d | jqOutput:\n{ \u0026#34;value\u0026#34;: \u0026#34;away\u0026#34;, \u0026#34;timestamp\u0026#34;: 1698765433000, \u0026#34;replica\u0026#34;: \u0026#34;ad-campaign-dc2\u0026#34; }How Conflict Resolution Works Under the Hood# LWW-Register Algorithm# The conflict resolution logic in lww_register.go:30-39:\nfunc (r *LWWRegister) Update(value interface{}, timestamp int64, replica string) bool { // Rule 1: Accept if timestamp is newer if timestamp \u0026gt; r.Timestamp { r.Value = value r.Timestamp = timestamp r.Replica = replica return true } // Rule 2: If timestamps equal, use replica ID as tiebreaker if timestamp == r.Timestamp \u0026amp;\u0026amp; replica \u0026gt; r.Replica { r.Value = value r.Replica = replica return true } // Rule 3: Reject stale updates return false }Key Properties:\nCommutative: Order of updates doesn\u0026rsquo;t matter Associative: Grouping of updates doesn\u0026rsquo;t matter Idempotent: Applying the same update multiple times is safe Deterministic: All replicas converge to the same value G-Counter Merge Algorithm# The merge logic in g_counter.go:\nfunc (c *GCounter) Merge(replica string, count int64) bool { current := c.Counts[replica] // Only accept higher counts (monotonic) if count \u0026gt; current { c.Counts[replica] = count return true } return false } func (c *GCounter) GetValue() int64 { total := int64(0) for _, count := range c.Counts { total += count } return total }Key Properties:\nMonotonic: Values only increase Convergent: All replicas reach the same total Partition-tolerant: Works across network splits Real-World Use Cases# 1. User Presence System# # User goes online in US datacenter curl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/lww:user:alice:status\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#34;{\\\u0026#34;value\\\u0026#34;:\\\u0026#34;online\\\u0026#34;,\\\u0026#34;timestamp\\\u0026#34;:$(date +%s)000,\\\u0026#34;replica\\\u0026#34;:\\\u0026#34;us-east-1\\\u0026#34;}\u0026#34; | base64)\u0026#39;\u0026#34;}\u0026#39; # User goes away in EU datacenter (newer timestamp wins) curl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/lww:user:alice:status\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#34;{\\\u0026#34;value\\\u0026#34;:\\\u0026#34;away\\\u0026#34;,\\\u0026#34;timestamp\\\u0026#34;:$(($(date +%s)+5))000,\\\u0026#34;replica\\\u0026#34;:\\\u0026#34;eu-west-1\\\u0026#34;}\u0026#34; | base64)\u0026#39;\u0026#34;}\u0026#39;All clients worldwide see the latest status in real-time!\n2. Distributed Analytics# # Track impressions across regions curl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/counter:campaign-123:impressions\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;us-east-1\u0026#34;,\u0026#34;count\u0026#34;:1500}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39; curl -X PUT \u0026#34;http://localhost:8002/api/v1/ad-campaign-dc2/kv/counter:campaign-123:impressions\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#39;{\u0026#34;replica\u0026#34;:\u0026#34;eu-west-1\u0026#34;,\u0026#34;count\u0026#34;:2300}\u0026#39; | base64)\u0026#39;\u0026#34;}\u0026#39; # Global total: 3800 impressions3. Feature Flags# # Enable feature in production curl -X PUT \u0026#34;http://localhost:8001/api/v1/ad-campaign-dc1/kv/lww:feature:new-ui\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;value\u0026#34;: \u0026#34;\u0026#39;$(echo -n \u0026#34;{\\\u0026#34;value\\\u0026#34;:true,\\\u0026#34;timestamp\\\u0026#34;:$(date +%s)000,\\\u0026#34;replica\\\u0026#34;:\\\u0026#34;control-plane\\\u0026#34;}\u0026#34; | base64)\u0026#39;\u0026#34;}\u0026#39;Feature flag changes propagate globally within milliseconds!\nTry It Yourself# # Clone and run the example git clone https://github.com/ankur-anand/unisondb.git cd unisondb CGO_ENABLED=1 go build -o unisondb ./cmd/unisondb # Start the demo cd cmd/examples/crdt-multi-dcWatch the magic happen as conflicts resolve themselves and state converges across datacenters!\nAdditional Resources# UnisonDB GitHub Repository CRDT Research Papers ZeroMQ Guide Have questions or want to contribute? Open an issue on GitHub or join our community discussions!\nBuilt with UnisonDB.\n"}]